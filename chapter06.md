# 第6章 モバイル・エッジ端末への最適化

## 6.1 省メモリ戦略
モバイル・エッジ環境ではメモリ容量が限られるため、モデルのサイズ削減と推論時のピークメモリ抑制が重要である。`ncnnoptimize`でのレイヤー融合やINT8量子化、`Option::use_packing_layout`によるSIMD効率化が基本施策となる。さらに`Net::opt.use_winograd_convolution = false`などメモリを消費する最適化をオフにし、代わりに逐次畳み込みを使用する場合もある。推論ロジックでは`Extractor::set_light_mode(true)`で中間テンソルを即時開放し、複数モデルを同時ロードしないよう設計する。

## 6.2 エネルギー効率と発熱対策
スマートフォンやバッテリー駆動のデバイスでは、推論負荷が高いと発熱やバッテリー消費が顕著に現れる。`Option::num_threads`を端末のbig.LITTLE構成に合わせて調整し、バックグラウンド実行時はスレッド数を減らす。Vulkanを有効にするとGPU計算によりCPU負荷が下がるが、すべての端末で効果があるわけではないため、ベンチマークで温度と消費電力を確認する。フレームレートや推論頻度を適応制御し、ユーザー操作が少ないときは推論間隔を伸ばすといった省エネ戦略も有効だ。

## 6.3 レイテンシ改善テクニック
リアルタイム処理では2桁ミリ秒以下のレイテンシが求められることが多い。入出力解像度を最適化し、不要なレイヤーを削除することが基本である。ncnnの`opt.use_local_pool_allocator`を有効にすると、頻繁に使うメモリブロックを各スレッドに割り当てられ、メモリ排他のオーバーヘッドを軽減できる。前処理と推論を並行実行するためにスレッドパイプラインを組み、CPUのアイドル時間を最小化する。推論後の後処理は可能な限りSIMD化し、NMSなどのボトルネック部分はOpenMPやVulkan Computeで分散させる。

## 6.4 デバイス別チューニング
ARMv8.2-A以降の端末ではFP16命令セットが利用可能で、`use_fp16_storage`と`use_fp16_arithmetic`を組み合わせると高速化が期待できる。x86ベースのエッジゲートウェイではAVX2/AVX-512最適化が効く一方、消費電力が課題になるためCPUのPステートを管理する。NPUやDSPを搭載したSoCの場合、ncnnのCPU/GPU実装よりもオンボード推論エンジンを利用した方が効率的な場合があるため、ハイブリッド構成としてncnnをフォールバックに用意するケースが多い。

## 6.5 Vulkan最適化の実践
Vulkanバックエンドを最大限活用するには、コマンドバッファの再利用とパイプラインキャッシュが鍵になる。`vkdev->set_default_allocator`で専用アロケータを設定し、ヒープの断片化を防ぐ。`ncnn::Option::use_vulkan_compute = true`と同時に、レイヤーごとに`set_vulkan_device`でパイプラインを初期化する処理を初回起動で済ませておくと、推論中の遅延が減る。GPUの計算能力に合わせてワークグループサイズを調整するため、ベンチマークを取りながら`VK_NCNN_SHADER_RESOURCE`マクロでチューニングする。

## 6.6 モデルの分割・ストリーミング
大規模モデルをそのまま端末に搭載できない場合、レイヤーを複数パートに分割して段階的に推論する手法がある。前段の特徴抽出を端末で実行し、後段をクラウドにオフロードするハイブリッド構成も一案だ。通信遅延が許容できない場合は、端末内で分割したモデルを順次ロードしながらストリーミング推論を行う。ncnnはモデル読み込みが高速なため、パーツを切り替えながら推論するユースケースにも適している。

## 6.7 プロファイリングと自動テスト
最適化の効果を測定するために、`benchncnn`や`ncnn::Profiler`を活用してレイヤーごとの処理時間を可視化する。Androidでは`systrace`や`perfetto`、iOSでは`Instruments`を併用し、CPU/GPUの利用状況を分析する。CIでは各ビルドごとにベンチマークを自動実行し、レイテンシやメモリの回帰を検知する仕組みを作る。テスト入力として実際の運用データを用意し、量子化モデルやVulkan有効時の結果も比較しておく。

## 6.8 本章のまとめ
本章ではモバイル・エッジ端末でncnnを最適化するための手法を紹介した。省メモリや省電力、レイテンシ短縮、デバイス別チューニング、Vulkan最適化、モデル分割、プロファイリングなど多角的なアプローチを組み合わせることで、ユーザー体験の向上と運用安定化が可能になる。次章では測定結果を踏まえたパフォーマンスチューニングとプロファイリングの具体的な手法を掘り下げる。
