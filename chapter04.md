# 第4章 推論エンジンの仕組み

## 4.1 NetとExtractorの役割
ncnnの推論処理は`Net`クラスと`Extractor`クラスを中心に構成される。`Net`はモデルの構造と重みを保持するコンテナで、`load_param`と`load_model`により`param`ファイルと`bin`ファイルを読み込む。`Extractor`は1回の推論リクエストを表現し、入力テンソルを設定してレイヤーを順次実行し、出力を取得する。`Extractor`はスレッド安全ではないが、`Net`から複数作成して並行処理させることが想定された設計になっている。これによりマルチスレッド環境での高スループット推論が可能になる。

## 4.2 Layer登録とファクトリ
ncnnでは各演算が`Layer`基底クラスを継承した派生クラスとして実装される。`layer_registry`がレイヤー名と生成関数をマッピングしており、`param`ファイルのレイヤー名に応じて該当クラスがインスタンス化される。たとえば`Convolution`や`ReLU`、`Pooling`などの標準レイヤーが登録されており、新しい演算を追加する際は`DEFINE_LAYER_CREATOR`マクロを用いて登録処理を行う。このファクトリ機構によって、変換済みモデルのレイヤー構造と実装が動的に紐付けられる。

## 4.3 Blobとメモリアロケーション
ncnnではテンソルを`Mat`クラスで表現し、内部的には`Blob`構造体が形状やメモリ管理フラグを保持する。推論実行時には`Blob`の参照カウントを追跡し、不要になったバッファを再利用することで動的メモリ割り当てを抑えている。`UnlockedPoolAllocator`と`PoolAllocator`が短期・長期のメモリプールを提供し、頻繁に使うバッファはアロケータに返却されて再利用される。これにより、組み込みデバイスでも安定したメモリ消費を実現している。

## 4.4 スレッドスケジューリングと並列化
`Option`構造体の`num_threads`設定により、ncnnはOpenMPや独自スレッドプールを使って畳み込みなど計算量の大きいレイヤーを並列化する。内部では`ThreadPool`がタスクをワーカーに分配し、行列演算やWinograd変換、GEMMなどをスレッド間で分担する。ARM上ではNEON命令を活かした行列乗算カーネルが用意され、x86ではSSE/AVX最適化が利用される。並列化効果を最大化するため、ベクトル幅に合わせたブロッキングやキャッシュ最適化が施されている。

## 4.5 Vulkanバックエンドの実行フロー
Vulkanバックエンドを有効にすると、`VkAllocator`と`VkCompute`がGPUメモリ管理・コマンド発行を担当する。各レイヤーは専用のVulkan pipelineを持ち、SPIR-VシェーダーがGPUでの計算を実現する。`VkPipelineCache`によるパイプライン再利用や、`VkTransfer`によるデータ転送最適化が行われ、CPU・GPU間の同期コストを最小限に抑えている。Vulkan実行時も`Extractor`のインターフェースは変わらず、内部的にCPUパスとGPUパスを切り替えて処理する。

## 4.6 精度とデータ型サポート
ncnnの内部表現は32bit浮動小数点が基本だが、16bit浮動小数点（FP16）やINT8量子化に対応する。FP16はHalf精度演算ユニットを持つGPUで特に効果的で、`Option`の`use_fp16_storage`や`use_fp16_arithmetic`を設定することで有効化される。INT8推論は量子化テーブルを利用してスケーリング計算を行い、畳み込み演算の一部に8bit整数を活用する。データ型の切り替えはレイヤー単位で制御され、一部レイヤーは精度要件からFloat32にフォールバックする。

## 4.7 中間出力の取得とデバッグ
`Extractor::extract`は特定レイヤーの出力を取得するAPIを提供しており、デバッグや可視化に活用できる。`extractor.input("data", mat)`で入力を設定し、`extractor.extract("prob", out)`などとすることで最終出力が得られる。また、`Extractor::set_light_mode(true)`を有効にすると、中間`Blob`を即時解放してメモリ使用量を抑えることができる。推論途中の一致確認には、中間ノードの値を取得してPyTorch側の対応レイヤーと比較し、誤差位置を特定する手法が一般的だ。

## 4.8 本章のまとめ
本章ではncnnの推論エンジン内部構造を解説した。`Net`と`Extractor`の責務分担、レイヤーファクトリ、メモリプール、並列化、Vulkanバックエンド、精度切り替えといった要素が相互に連携し、端末上で効率的な推論を実現している。次章では実際にAPIを用いた推論アプリの開発手順とコード例を紹介し、ここで学んだ内部構造を活かした実装を行う。
