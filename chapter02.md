# 第2章 環境構築とツールチェーン

## 2.1 開発ターゲットの選定
ncnnはLinux、Windows、macOS、Android、iOS、組み込みLinuxなど多様なプラットフォームで動作する。最初にどの端末へデプロイするかを明確にし、CPUアーキテクチャ（ARM、x86、RISC-Vなど）とGPUサポートの有無を整理することが重要だ。例えばAndroidスマートフォンをターゲットにする場合はARM64とVulkanの利用可否、エッジデバイスではOpenWrtやYoctoのようなディストリビューションとの相性を確認しておく。ターゲットが決まればビルドフラグやツールチェーンの選択肢が自然に定まる。

## 2.2 必要な依存ツール
ncnn本体は外部依存が少ないが、ビルドにはCMake 3.10以降とC++14対応コンパイラが必要になる。LinuxではGCCまたはClang、WindowsではVisual StudioのMSVC、macOSではXcodeのClangが一般的だ。モデル変換にはPythonとONNX Runtime、PyTorch、TensorFlowなど学習フレームワークが必要になることが多い。加えてVulkanを利用する場合はLunarGのVulkan SDK、Metalバックエンドを使う場合は最新のXcodeツールチェーンを入れておくとよい。パッケージマネージャ（apt、Homebrew、Chocolatey等）を活用すると依存管理が容易になる。

## 2.3 ソースコードの取得とバージョン管理
公式リポジトリはGitHub上にあり、安定版リリースと開発版ブランチが提供されている。複数プロジェクトで共通のncnnバージョンを使う場合はサブモジュールとして管理し、タグ付けされたリリースに固定することでビルド結果の再現性を確保できる。Tencentが配布する`benchmark`や`examples`サブプロジェクトも合わせて取得しておくと、動作検証時に便利だ。組織内で改造を加える際はフォークリポジトリを用意し、上流へのパッチ送出を想定した運用体制を整えておく。

## 2.4 デスクトップ向けビルド手順
典型的なLinux環境では次のようにCMakeを使ってビルドする。
```bash
mkdir build && cd build
cmake -DCMAKE_BUILD_TYPE=Release -DNCNN_VULKAN=ON ..
make -j$(nproc)
```
WindowsではVisual Studioの開発者コマンドプロンプトから`cmake -G "Visual Studio 17 2022"`を実行し、生成されたソリューションをビルドする。macOSでは`-DNCNN_OPENMP=ON`などマルチスレッド関連のフラグを適宜設定する。ビルド成果物`libncnn.a`や`ncnn.lib`はアプリケーションにスタティックリンクでき、`examples`フォルダにあるサンプルを実行することで動作確認が行える。

## 2.5 モバイル向けクロスコンパイル
Android向けにはAndroid NDK r21以降を用い、CMakeのツールチェーンファイルを指定してビルドする。`-DANDROID_ABI=arm64-v8a`や`armeabi-v7a`といったABIを切り替え、Vulkanを同時に有効化する場合はAPK側で`android:usesCleartextTraffic="true"`など必要な設定を加える。iOSではCMakeとXcodeを組み合わせ、`-DNCNN_OPENMP=OFF`でOpenMPを無効化したうえでStatic Libraryを生成する。モバイルアプリへ組み込む際はJNIやObjective-C++ブリッジ層を通じてncnnのC++ APIを呼び出す構成が一般的だ。

## 2.6 GPUバックエンドの有効化
Vulkanバックエンドを利用する場合、ターゲットデバイスに対応ドライバが存在するか事前に確認し、必要に応じて`vk_instance`の初期化コードや権限設定を追加する。Androidでは`VK_KHR_portability_subset`拡張の有無が挙動に影響することがあり、複数端末での検証が欠かせない。MetalバックエンドはmacOS/iOSで有効化でき、シェーダーコードはSPIR-VからMetal Shading Languageへ自動変換される。GPU利用時はバッファ転送のオーバーヘッドや精度差異を考慮し、CPUパスとのフォールバック機構を実装しておくと運用が安定する。

## 2.7 ベンチマークと動作確認
ncnnには公式の`benchncnn`ツールが付属しており、レイヤー別の処理時間やメモリ消費を計測できる。ターゲットデバイスごとにベンチ結果を蓄積し、OSアップデートやドライバ更新後にリグレッションがないか確認する習慣を持つとよい。また、`examples/squeezenet`など軽量モデルを用いて起動時間や推論レイテンシを測定すれば、アプリケーション統合前にパフォーマンスの目安を掴める。CI環境で自動ベンチマークを走らせる場合は、サンドボックス内で`ncnnoptimize`や量子化ツールも併せて検証しておくと実運用に近い評価が行える。

## 2.8 モデル変換パイプラインの整備
多くのプロジェクトではPyTorchやTensorFlowで学習したモデルをONNXへエクスポートし、ncnn付属の`onnx2ncnn`、`ncnnoptimize`、`ncnn2mem`といったツールでパラメータを最適化する。量子化やチャンネルプルーニングを取り入れる場合は、学習フレームワーク側で対応するスクリプトを整備し、CI/CDで自動変換するパイプラインを構築するとミスが少ない。モデル更新時にはハッシュ値やバージョンをメタデータとして保持し、アプリ内の推論コードとの互換性を担保する運用が推奨される。

## 2.9 本章のまとめ
本章ではncnnを開発・運用するための環境構築手順とツールチェーンを整理した。ターゲットプラットフォームの選定から始まり、デスクトップ・モバイル向けビルド、GPUバックエンドの設定、ベンチマークやモデル変換フローまでを網羅的に紹介した。次章では実際に学習済みモデルをncnn形式に変換するプロセスに踏み込み、変換時の注意点とデバッグ手法を解説する。
